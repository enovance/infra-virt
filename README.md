[![Build Status](https://travis-ci.org/enovance/infra-virt.svg?branch=master)](https://travis-ci.org/enovance/infra-virt)

# About

Tools to deploy a virtual infrastructure based on a YAML description file. It supports
the following features:

- PXE or boot on image (QCOW2)
- network configuration (bonding, 802.1Q, Jumbo Frame)
- Nested KVM
- snapshot support

## A set of components

- virtualizor.py: create the infrastructure from the YAML file
- virtualize.sh: helper designed to deploy an OpenStack [SpinalStack](http://spinal-stack.readthedocs.org/en/latest/)
- collector.py: create automatically the infrastructure YAML from an existing SpinalStack environment directory.
- scenarios: light scripts to replay/validate an OpenStack upgrade

# Prerequisites

On the local machine:

You must install libvirt-python first.

```sh
pip install -r requirements.txt
```

On the Hypervisor:

We use a Fedora 21 with the following extra packages:

- libvirt
- mtools
- qemu-kvm
- iptables-services

You will need to disable firewalld and enable libvirt:

```sh
sudo systemctl enable libvirtd
sudo systemctl start libvirtd

sudo service iptables save
sudo systemctl disable firewalld
sudo systemctl enable iptables
sudo systemctl stop firewalld
sudo systemctl start iptables
```

## User account

At this point, you must create the user on the Hypervisor this way:

* sudo with no password. e.g: `joe     ALL=(ALL)       NOPASSWD: ALL`
* ssh-key with no password `ssh-keygen`
* ssh-key registred in the /root/.ssh/authorized_keys file

You must be able to run the following command with no password:

```sh
$ ssh root@localhost uname
$ sudo uname
```

# components

`collector.py` is used to extract information from a Spinal Stack environment directory
and generate the associated YAML infrastructure file.

## collector.py

```sh
usage: collector.py [-h] [--config-dir CONFIG_DIR] [--output-dir OUTPUT_DIR]
                    --sps-version SPS_VERSION [--qcow]
                    [--parse-configure-files] [--images-url IMAGES_URL]
Collect architecture information from the edeploy directory as generated by
config-tools/download.sh.
optional arguments:
  -h, --help            show this help message and exit
  --config-dir CONFIG_DIR
                        The config directory absolute path.
  --output-dir OUTPUT_DIR
                        The output directory of the virtual configuration.
  --sps-version SPS_VERSION
                        The SpinalStack version.
  --qcow                Boot on qcow image.
  --parse-configure-files
                        Enable experimental .configure file parsing.
  --images-url IMAGES_URL
                        Url of the qcow images.
```

## virtualizor.py

`virtualizor.py` is the tool in charge of deploying the infrastructure described in the YAML
file on a libvirt hypervisor.

```sh
usage: virtualizor.py [-h] [--cleanup] [--pub-key-file PUB_KEY_FILE]
                      [--prefix PREFIX] [--public_network PUBLIC_NETWORK]
                      input_file target_host

Deploy a virtual infrastructure.

positional arguments:
  input_file            the YAML input file, as generated by collector.py.
  target_host           the name of the libvirt server. The local user must be
                        able to connect to the root account with no password
                        authentification.

optional arguments:
  -h, --help            show this help message and exit
  --cleanup             existing resources with the same prefix will be
                        removed first. (default: False)
  --pub-key-file PUB_KEY_FILE
                        the path to the SSH public key file that must be
                        injected in the install-server root and jenkins
                        account (default: [])
  --prefix PREFIX       optional prefix to put in the machine and network to
                        avoid conflict with resources create by another
                        virtualizor instance. Thanks to this parameter, the
                        user can run as virtualizor as needed on the same
                        machine. (default: default)
  --public_network PUBLIC_NETWORK
                        allow the user to pass the name of a libvirt NATed
                        network that will be used as a public network for the
                        install-server. This public network will by attached
                        to eth1 interface and IP address is associated using
                        the DHCP. (default: nat)
```

## virtualize.sh

`virtualize.sh` is a script built on top of `virtualizor.py` to play SpinalStack deployment and upgrade.

```sh
usage: ./virtualize.sh [OPTION]
Collect architecture information from the edeploy directory as generated
by config-tools/download.sh and use the virtulizor.py to boostrap a SpS platform.

arguments:
    -h|--help                     Show this help
    -H|--hypervisor=name          Set the hypervisor hostname, default (localhost)
    -d|--debug                    Set the debug mode for this script, default: disabled
    -v|--virt=virt_platform.yml   Set the path to the infra's yaml, default: (virt_platform.yml)
    -e|--extra='--cleanup'        Add extra parameters to virtulizor.py
    -p|--prefix                   Change the platform's prefix, default: unix user
    -s|--socks                    Create a socks server to test your platform
    -t|--tempest                  Launch the sanity job at the end of a deployement
    -l|--logs                     Fetch the logs from elasticesearch and upload them
                                  into Swift

For example:
./virtualize.sh -H localhost -e '--cleanup' I.1.2.1/
will deploy the environment from the I.1.2.1/ directory.

and
./virtualize.sh -H localhost -e '--cleanup' -w ../config-tools/ --sockets --tempest
will deploy the env in your directory config-tools/, create a tunnel socks and launch tempest
```

# Example

## Create a simple infrastructure

```sh
./virtualizor.py virt_platform_pxe.yml.sample localhost --pub-key-file ~/.ssh/id_rsa.pub --cleanup
```

## Spinal Stack

```sh
$ cd ~
$ git clone https://github.com/enovance/config-tools.git
$ cd config-tools/
$ git checkout I.1.3
$ ./download.sh I.1.3.0 deployment-3nodes-D7.yml version=D7-I.1.3.0
```

It generates a directory 'top/' in the current directory.

```sh
$ cd ~
$ git clone https://github.com/enovance/infra-virt.git
$ cd infra-virt/
$ ./collector.py --config-dir ~/config-tools/top/etc --sps-version D7-I.1.3.0
Virtual platform generated successfully at 'virt_platform.yml' !
```

It will generate a file 'virt_platform.yml' which describe the corresponding virtual
platform. You may take a look at a sample in the virtualization directory.

```sh
$ cd ~/infra-virt/
$ ./virtualizor.py virt_platform.yml my-hypervisor-node --cleanup --pub-key-file ~/.ssh/boa.pub
```

If your node are properly installed you can now connect to them via connect.sh.
The `connect.sh` script will help you to find the IP and connect on a virtual server. Provide
the profile declared in `virt_platform.yml` and the infra-virt prefix.

```sh
./connect.sh default router
```

The prefix is setted by `virtualizor.py` with `--prefix` argument. By default the prefix value is `default`.

# Troubleshooting

**Issue :**

```
./virtualizor.py ...
libvirt.libvirtError: internal error: Unable to apply rule 'The name org.fedoraproject.FirewallD1 was not provided by any .service files'
```

**Solution :** libvirtd restart is needed between firewalld stopped and iptables started.

**Issue :**

```
WARNING:root:Images url is not provided by the infra description, no images will be downloaded from the hypervisor.
qemu-img: Could not open '/var/lib/libvirt/images/....qcow2': Could not open backing file: Could not open '/var/lib/libvirt/images/....qcow2': No such file or directory

```

**Solution :** In case you specify an image in the virt platform yaml, you have 2 solution.

  * Have your image locally on the hypervisor `/var/lib/libvirt/images` directory.
  * Add `images-url` in your yaml at root level. `images-url` is the base url for all your images.

**Issue :** I'm unable to find my router IP address with `connect.sh`.

**Solution :** Have a look in dnsmasq leases file : `/var/lib/libvirt/dnsmasq/nat.leases`
